{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96bd388",
   "metadata": {},
   "outputs": [],
   "source": [
    "from obspy.core import Stream, read\n",
    "from scipy.interpolate import interp1d\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc1b86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_files = '/Users/sydneydybing/StrainProject/StrainData/'\n",
    "quake_folders = np.genfromtxt('/Users/sydneydybing/StrainProject/quake_folders.txt', dtype=str)\n",
    "stas = np.genfromtxt('/Users/sydneydybing/StrainProject/stations.txt', dtype=str)\n",
    "chans = ['BS1', 'BS2', 'BS3', 'BS4']\n",
    "\n",
    "quake_folders_test = ['109_2010_6.5']\n",
    "stas_test = ['B028']\n",
    "\n",
    "quake_folders_test_2 = ['34_2006_5.5', '112_2010_7.2', '185_2014_6.9']\n",
    "stas_test_2 = ['B003', 'B088', 'B935']\n",
    "\n",
    "bad_stachan = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f294e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for quake in quake_folders_test:\n",
    "    for sta in stas_test:\n",
    "        for chan in chans:          \n",
    "            \n",
    "            g = Stream()\n",
    "            \n",
    "            try:\n",
    "            \n",
    "                g = read(path_to_files + quake + '/' + sta + '_' + chan + '.mseed')\n",
    "                \n",
    "                #g.plot()\n",
    "                \n",
    "                # Equations from Barbour and Crowell to convert to strain\n",
    "                # R = ratio of the gap between the fixed-capacitance plates and instrument diameter (0.087 m)\n",
    "                # Going to use 100 microns for gap for now (10**(-4) m)\n",
    "                \n",
    "                if (sta == 'B001') or (sta == 'B003') or (sta == 'B004') or (sta == 'B005') \\\n",
    "                    or (sta ==  'B006') or (sta == 'B007') or (sta == 'B009') or (sta == 'B010') \\\n",
    "                    or (sta == 'B011') or (sta == 'B012') or (sta == 'B018') or (sta == 'B022') \\\n",
    "                    or (sta == 'B024') or (sta == 'B035') or (sta == 'B081') or (sta == 'B082') \\\n",
    "                    or (sta == 'B086') or (sta == 'B087'):\n",
    "                    \n",
    "                    R = 2*10**(-4) / 0.087\n",
    "                                    \n",
    "                else:\n",
    "                    \n",
    "                    R = 10**(-4) / 0.087\n",
    "                                \n",
    "                C = 10**8\n",
    "                \n",
    "                # Calculating new linear extensional strains (turns from a Stream into a numpy array)\n",
    "                \n",
    "                e = R * (((g[0].data)/C)/(1 - (g[0].data)/C))\n",
    "                \n",
    "                times = range(g[0].stats.npts)\n",
    "                times = np.asarray(times)/(g[0].stats.sampling_rate)\n",
    "                                                     \n",
    "                ## Fixing the data ##\n",
    "                \n",
    "                # Identifying stations with issues using derivatives\n",
    "                \n",
    "                # Taking the derivative of the timeseries\n",
    "                \n",
    "                deriv_e = np.diff(np.hstack((e[0],e)))\n",
    "             \n",
    "                deriv_e_min = np.min(deriv_e)\n",
    "                deriv_e_max = np.max(deriv_e)\n",
    "                deriv_e_avg = np.average(deriv_e)\n",
    "                \n",
    "                if deriv_e_min <= -0.00025 or deriv_e_max >= 0.00025: # better to do this with averages or #s?\n",
    "                    \n",
    "                    bad_label = quake + '_' + sta + '_' + chan \n",
    "                    bad_stachan.append(bad_label)\n",
    "                    \n",
    "                else:\n",
    "                    pass\n",
    "                \n",
    "                if quake + '_' + sta + '_' + chan in bad_stachan:\n",
    "                    \n",
    "                    # Finding the value of the messed up samples\n",
    "                    \n",
    "                    data_min = np.amin(e)\n",
    "                    \n",
    "                    # Finding the indices of the messed up samples\n",
    "                    \n",
    "                    i = np.where(e <= data_min)[0]\n",
    "                    \n",
    "                    num_bad = i.shape[0]\n",
    "                    \n",
    "                    print(\"Bad station & channel - event \" + quake + ': ' + sta + '_' + chan + '. ' + str(num_bad) + ' bad samples')\n",
    "                    \n",
    "                    # Deleting the bad samples from the data and the times arrays\n",
    "                    \n",
    "                    e_clean = np.delete(e, i)\n",
    "                    times_clean = np.delete(times, i)\n",
    "                                    \n",
    "                    # Now fill in the gaps with the linear interpolation\n",
    "                    \n",
    "                    f = interp1d(times_clean, e_clean)\n",
    "                    e_fill = f(times)\n",
    "                    e = e_fill\n",
    "                    \n",
    "                else: \n",
    "                    print(\"Good station & channel - event \" + quake + ': ' + sta + '_' + chan)\n",
    "                    \n",
    "                # Normalizing unfiltered data\n",
    "                \n",
    "                norm_value = e[0]\n",
    "                data_length = e.shape\n",
    "                normalize = np.full(data_length, norm_value)\n",
    "                \n",
    "                e_norm = np.subtract(e, normalize)\n",
    "                \n",
    "                # Plotting normalized fixed data\n",
    "                \n",
    "                plt.plot(times, e_norm*10**6)\n",
    "                plt.xlim(0.,300.)\n",
    "                plt.ylim()\n",
    "                plt.xlabel('Time (s) from Earthquake Origin')\n",
    "                plt.ylabel('Microstrain ($10^{-6}$ m/m)')\n",
    "                plt.title(quake + ' Earthquake at PBO Station ' + sta + '_' + chan)\n",
    "    \n",
    "                e_fixed = g.copy()\n",
    "                #g.plot()\n",
    "                e_fixed[0].data = e_norm\n",
    "                e_fixed.plot()\n",
    "                #e_fixed.write('/Users/sydneydybing/StrainProject/StrainData/Processed/' + quake + '/' + sta + '_' + chan + '.mseed', format='MSEED')\n",
    "\n",
    "            except: \n",
    "            \n",
    "                print(quake + \" no station \" + sta)                        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf1ebf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bad_stachan)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
