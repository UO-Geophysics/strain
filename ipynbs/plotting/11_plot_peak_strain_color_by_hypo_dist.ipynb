{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eadbc20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from obspy.core import Stream, read\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl \n",
    "from matplotlib.colors import Normalize\n",
    "import pandas as pd\n",
    "import os \n",
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e32f87ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_files = '/Users/sydneydybing/StrainProject/2024/'\n",
    "\n",
    "earthquakes = pd.read_csv(path_to_files + 'M6_catalog_2004-2024.csv', dtype = str)\n",
    "\n",
    "weird_events_only = False\n",
    "if weird_events_only:\n",
    "    earthquakes = earthquakes.iloc[[4,15]]\n",
    "\n",
    "small_test = False\n",
    "if small_test:\n",
    "    earthquakes = earthquakes[5:7]\n",
    "    \n",
    "redo_picks = True\n",
    "if redo_picks:\n",
    "    earthquakes = earthquakes.iloc[[3,5,6,8,10,17,19,20,21,24,25,26,27,29]]\n",
    "\n",
    "origin_times = earthquakes.time.values\n",
    "mags = earthquakes.mag.values\n",
    "\n",
    "bsm_mda = pd.read_csv(path_to_files + 'bsm_metadata.csv')\n",
    "NA_only = bsm_mda.loc[bsm_mda['LONG'] < -110]\n",
    "stas = NA_only['BNUM'].values\n",
    "\n",
    "eqs_test = earthquakes[4:5]\n",
    "ots_test = origin_times[4:5]\n",
    "mags_test = mags[4:5]\n",
    "rows_for_extra_times = [8,9,14,16]\n",
    "\n",
    "dist_array = np.load('/Users/sydneydybing/StrainProject/2024/NA_evt-sta_dist_array_less500km_withdata.npy')\n",
    "\n",
    "# Array order:\n",
    "\n",
    "# 0. Earthquake identifier\n",
    "# 1. Earthquake origin time\n",
    "# 2. Earthquake latitude\n",
    "# 3. Earthquake longitude\n",
    "# 4. Earthquake magnitude\n",
    "# 5. Station name\n",
    "# 6. Station latitude\n",
    "# 7. Station longitude\n",
    "# 8. Hypocentral distance (km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddc60638-fb3e-4f25-bf5a-53b4a19f83ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(439, 9)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "117ddb00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Earthquake 1/14\n",
      "Earthquake 2/14\n",
      "Earthquake 3/14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Earthquake 4/14\n",
      "Earthquake 5/14\n",
      "Earthquake 6/14\n",
      "Earthquake 7/14\n",
      "Skipping 2014-08-24 B076\n",
      "Earthquake 8/14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Earthquake 9/14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Earthquake 10/14\n",
      "Earthquake 11/14\n",
      "Earthquake 12/14\n",
      "Earthquake 13/14\n",
      "Earthquake 14/14\n"
     ]
    }
   ],
   "source": [
    "cmap = plt.get_cmap('turbo', 500) \n",
    "\n",
    "for idx in range(len(earthquakes)):\n",
    "    \n",
    "    no_data = False\n",
    "    \n",
    "    if idx >= 31: # No data available for 4 earliest earthquakes\n",
    "        no_data = True\n",
    "        \n",
    "    if no_data == False:\n",
    "        fig = plt.figure(figsize = (10,6), dpi = 300, facecolor = 'white', num = 1, clear = True)\n",
    "        ax = fig.add_subplot(111)\n",
    "        \n",
    "    ot = origin_times[idx]\n",
    "    print('Earthquake ' + str(idx+1) + '/' + str(len(mags)))\n",
    "    \n",
    "    if idx in rows_for_extra_times:\n",
    "        cut_ot = ot[:13]\n",
    "    else:\n",
    "        cut_ot = ot[:10]\n",
    "    \n",
    "    eq_id = str(cut_ot) + '_M' + str(mags[idx])\n",
    "#     print(eq_id)\n",
    "        \n",
    "    # Find rows that match this event in the array with the hypocentral distances\n",
    "    \n",
    "    i = np.where(dist_array[:,0] == eq_id)[0]\n",
    "#     print(dist_array[i])\n",
    "        \n",
    "    for sta in stas:\n",
    "        \n",
    "        try:\n",
    "            \n",
    "            # Peak strain data\n",
    "        \n",
    "            pst = read(path_to_files + 'strain_data/peak/' + str(cut_ot) + '_M' + str(mags[idx]) + '/' + str(sta) + '.mseed')\n",
    "                \n",
    "        except:\n",
    "            continue # skips to next station\n",
    "\n",
    "        # Find row that matches this station within the rows of the right event\n",
    "\n",
    "        j = np.where(dist_array[i,5] == sta)[0]\n",
    "\n",
    "#             print(dist_array[i][j])\n",
    "\n",
    "        hypdist = float(dist_array[i][j][0][8])\n",
    "#         print(hypdist)\n",
    "        \n",
    "        int_hypdist = int(hypdist)\n",
    "#         print(int_hypdist)\n",
    "\n",
    "        pst_times = pst[0].times()\n",
    "        pst_data = pst[0].data\n",
    "\n",
    "        # Plot stations, but avoid plotting the weird stations for the two problem earthquakes\n",
    "\n",
    "        if idx == 4 and sta == 'B072' or sta == 'B076':\n",
    "            print('Skipping ' + str(cut_ot) + ' ' + str(sta))\n",
    "\n",
    "        elif idx == 15 and sta == 'B928':\n",
    "            print('Skipping ' + str(cut_ot) + ' ' + str(sta))\n",
    "\n",
    "        else:\n",
    "            ax.set_title('Earthquake ' + str(cut_ot) + '_M' + str(mags[idx]), fontsize = 18)\n",
    "            ax.plot(pst_times, pst_data*10**9, color = cmap(int_hypdist-1), label = sta)\n",
    "            ax.set_yscale('log')\n",
    "            ax.set_ylabel('Log of peak extensional\\nmicrostrain ($10^{-6}$)', fontsize = 15)\n",
    "            ax.set_xlabel('Time (s)', fontsize = 15)\n",
    "            ax.set_xlim(0,120)\n",
    "            ax.tick_params(labelsize = 13)\n",
    "            \n",
    "    # Plot after each earthquake\n",
    "    if no_data: \n",
    "        pass\n",
    "    else:\n",
    "        cbar = fig.colorbar(plt.cm.ScalarMappable(norm = Normalize(0, 500), cmap = cmap), ax = ax)\n",
    "        cbar.ax.tick_params(labelsize = 11)\n",
    "        cbar.ax.set_ylabel(ylabel = 'Hypocentral distance (km)', fontsize = 13)\n",
    "        ax.legend(loc = 'lower right', ncol = 2, fontsize = 12)\n",
    "#         plt.show();\n",
    "        plt.savefig(path_to_files + 'figures/peak_strain_plots/NA_M6_500km/rainbow_by_hypdist/' + str(cut_ot) + '_M' + str(mags[idx]) + '.png', format = 'PNG')\n",
    "        plt.close();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bee408",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
