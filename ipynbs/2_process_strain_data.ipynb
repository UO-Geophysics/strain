{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b96bd388",
   "metadata": {},
   "outputs": [],
   "source": [
    "from obspy.core import Stream, read\n",
    "from scipy.interpolate import interp1d\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os.path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdc1b86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_files = '/Users/sydneydybing/StrainProject/2024/'\n",
    "\n",
    "earthquakes = pd.read_csv(path_to_files + 'M6_catalog_2004-2024.csv', dtype = str)\n",
    "\n",
    "fix_dups = True\n",
    "if fix_dups:\n",
    "    earthquakes = earthquakes.iloc[[8,9,14,16]] # Earthquakes with same day and magnitude\n",
    "    \n",
    "origin_times = earthquakes.time.values\n",
    "mags = earthquakes.mag.values\n",
    "\n",
    "bsm_mda = pd.read_csv(path_to_files + 'bsm_metadata.csv')\n",
    "NA_only = bsm_mda.loc[bsm_mda['LONG'] < -110]\n",
    "stas = NA_only['BNUM'].values\n",
    "chans = ['BS1', 'BS2', 'BS3', 'BS4']\n",
    "\n",
    "stas_200_microns = NA_only.loc[NA_only['GAP(m)'] == 0.0002]['BNUM'].values\n",
    "\n",
    "earthquakes_test = earthquakes[:3]\n",
    "stas_test = ['B028']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5f294e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Earthquake 1/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sydneydybing/opt/anaconda3/lib/python3.8/site-packages/obspy/io/mseed/core.py:790: UserWarning: The encoding specified in trace.stats.mseed.encoding does not match the dtype of the data.\n",
      "A suitable encoding will be chosen.\n",
      "  warnings.warn(msg, UserWarning)\n",
      "/Users/sydneydybing/opt/anaconda3/lib/python3.8/site-packages/obspy/io/mseed/core.py:838: UserWarning: File will be written with more than one different encodings.\n",
      "This might have a negative influence on the compatibility with other programs.\n",
      "  warnings.warn(msg % 'encodings')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Earthquake 2/4\n",
      "Earthquake 3/4\n",
      "Earthquake 4/4\n"
     ]
    }
   ],
   "source": [
    "bad_stachan = []\n",
    "q = 0\n",
    "\n",
    "for idx in range(len(earthquakes)):\n",
    "    \n",
    "    ot = origin_times[idx]\n",
    "    print('Earthquake ' + str(idx+1) + '/' + str(len(mags)))\n",
    "    \n",
    "    for sta in stas:\n",
    "        \n",
    "        for chan in chans:\n",
    "            \n",
    "            q += 1\n",
    "            \n",
    "            try:\n",
    "                \n",
    "                if fix_dups:\n",
    "                    cut_ot = ot[:13]\n",
    "                else:\n",
    "                    cut_ot = ot[:10]\n",
    "                \n",
    "                eq_load_dir = path_to_files + 'strain_data/raw/' + str(cut_ot) + '_M' + str(mags[idx]) + '/' + str(sta) + '/'\n",
    "#                 print(eq_load_dir)\n",
    "                g = read(eq_load_dir + chan + '.mseed')\n",
    "#                 print('Raw data')\n",
    "#                 g.plot()\n",
    "                \n",
    "                # Equations from Barbour and Crowell to convert to strain\n",
    "                # R = ratio of the gap between the fixed-capacitance plates and instrument diameter (0.087 m)\n",
    "                \n",
    "                if sta in stas_200_microns:\n",
    "                    R = 2*10**(-4) / 0.087\n",
    "                                    \n",
    "                else:\n",
    "                    R = 10**(-4) / 0.087\n",
    "                                \n",
    "                C = 10**8\n",
    "                \n",
    "                # Calculating new linear extensional strains (turns from a Stream into a numpy array)\n",
    "                \n",
    "                e = R * (((g[0].data)/C)/(1 - (g[0].data)/C))\n",
    "                \n",
    "                times = range(g[0].stats.npts)\n",
    "                times = np.asarray(times)/(g[0].stats.sampling_rate)\n",
    "                                                     \n",
    "                ## Fixing the data ##\n",
    "                \n",
    "                # Identifying stations with issues using derivatives\n",
    "                \n",
    "                # Taking the derivative of the timeseries\n",
    "                \n",
    "                deriv_e = np.diff(np.hstack((e[0],e)))\n",
    "             \n",
    "                deriv_e_min = np.min(deriv_e)\n",
    "                deriv_e_max = np.max(deriv_e)\n",
    "                deriv_e_avg = np.average(deriv_e)\n",
    "                \n",
    "                if deriv_e_min <= -0.00025 or deriv_e_max >= 0.00025: # better to do this with averages or #s?\n",
    "                    \n",
    "                    bad_label = str(cut_ot) + '_M' + str(mags[idx]) + '.' + str(sta) + '.' + str(chan)\n",
    "                    bad_stachan.append(bad_label)\n",
    "                    \n",
    "                else:\n",
    "                    pass\n",
    "                \n",
    "                if str(cut_ot) + '_M' + str(mags[idx]) + '.' + str(sta) + '.' + str(chan) in bad_stachan:\n",
    "                    \n",
    "                    # Finding the value of the messed up samples\n",
    "                    \n",
    "                    data_min = np.amin(e)\n",
    "                    \n",
    "                    # Finding the indices of the messed up samples\n",
    "                    \n",
    "                    i = np.where(e <= data_min)[0]\n",
    "                    \n",
    "                    num_bad = i.shape[0]\n",
    "                    \n",
    "#                     print(\"Bad station & channel - event \" + str(ot[:10]) + '_M' + str(mags[idx]) + '_' + str(sta) + '_' + str(chan) + '. ' + str(num_bad) + ' bad samples')\n",
    "                    \n",
    "                    # Deleting the bad samples from the data and the times arrays\n",
    "                    \n",
    "                    e_clean = np.delete(e, i)\n",
    "                    times_clean = np.delete(times, i)\n",
    "                                    \n",
    "                    # Now fill in the gaps with the linear interpolation\n",
    "                    \n",
    "                    f = interp1d(times_clean, e_clean)\n",
    "                    e_fill = f(times)\n",
    "                    e = e_fill\n",
    "                    \n",
    "                else: \n",
    "                    pass\n",
    "#                     print(\"Good station & channel - event \" + str(ot[:10]) + '_M' + str(mags[idx]) + '_' + str(sta) + '_' + str(chan))\n",
    "                    \n",
    "                # Normalizing unfiltered data\n",
    "                \n",
    "                norm_value = e[0]\n",
    "                data_length = e.shape\n",
    "                normalize = np.full(data_length, norm_value)\n",
    "                \n",
    "                e_norm = np.subtract(e, normalize)\n",
    "                \n",
    "                # Plotting normalized fixed data\n",
    "                \n",
    "#                 plt.plot(times, e_norm*10**6)\n",
    "#                 plt.xlim(0.,300.)\n",
    "#                 plt.ylim()\n",
    "#                 plt.xlabel('Time (s) from Earthquake Origin')\n",
    "#                 plt.ylabel('Microstrain ($10^{-6}$ m/m)')\n",
    "#                 plt.title(str(ot[:10]) + '_M' + str(mags[idx]) + '_' + str(sta) + '_' + chan)\n",
    "    \n",
    "                e_fixed = g.copy()\n",
    "                e_fixed[0].data = e_norm\n",
    "#                 print('Fixed data')\n",
    "#                 e_fixed.plot()\n",
    "                \n",
    "                # Create folder for the event\n",
    "                eq_sta_save_dir = path_to_files + 'strain_data/processed/' + str(cut_ot) + '_M' + str(mags[idx]) + '/' + str(sta) + '/'\n",
    "#                 print(eq_sta_save_dir)\n",
    "                if os.path.isdir(eq_sta_save_dir):\n",
    "                    pass\n",
    "                else:\n",
    "                    os.makedirs(eq_sta_save_dir)\n",
    "                \n",
    "                e_fixed.write(eq_sta_save_dir + chan + '.mseed', format = 'MSEED')\n",
    "\n",
    "            except: \n",
    "                pass\n",
    "#                 print(str(ot[:10]) + '_M' + str(mags[idx]) + '_' + str(sta) + '_no_station')                        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bf1ebf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144\n",
      "1216\n"
     ]
    }
   ],
   "source": [
    "print(len(bad_stachan))\n",
    "print(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d58e2c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
