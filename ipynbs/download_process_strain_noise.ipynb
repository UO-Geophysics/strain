{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9119db09-4f08-46f5-ab3b-bb6a821c0e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Currently only set up to download Ridgecrest M7 stations to match SW4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "41268d60-460a-4f04-8896-aa4d12c0d41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from obspy.core import Stream, UTCDateTime, read\n",
    "from obspy.clients.fdsn import Client\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "f01a3e2b-93eb-4620-9aff-25e8a248a724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naming the client where the data will be coming from. Googling obspy fdsn will\n",
    "# list other options.\n",
    "\n",
    "client = Client('IRIS')\n",
    "\n",
    "# Reading in my info files - earthquakes is a list of the events I want to get data for,\n",
    "# which includes locations and origin times, and then stas is the list of stations I want\n",
    "# to pull data from. Chans is then the four strainmeter channels for these instruments.\n",
    "\n",
    "path_to_files = '/Users/sydneydybing/StrainProject/2024/'\n",
    "\n",
    "earthquakes = pd.read_csv(path_to_files + 'M6_catalog_2004-2024.csv', dtype = str)\n",
    "bsm_mda = pd.read_csv(path_to_files + 'bsm_metadata.csv')\n",
    "NA_only = bsm_mda.loc[bsm_mda['LONG'] < -110]\n",
    "stas = NA_only['BNUM'].values\n",
    "chans = ['BS1', 'BS2', 'BS3', 'BS4']\n",
    "\n",
    "noise_events = True\n",
    "\n",
    "fix_dups = False\n",
    "if fix_dups:\n",
    "    earthquakes = earthquakes.iloc[[8,9,14,16]] # Earthquakes with same day and magnitude\n",
    "    \n",
    "old_events = False # no data for these ones available\n",
    "if old_events:\n",
    "    earthquakes = earthquakes[-4:]\n",
    "    \n",
    "if noise_events == False:\n",
    "    earthquakes = earthquakes.iloc[[0,1,11,27]]\n",
    "    \n",
    "weird_events_only = False\n",
    "if weird_events_only:\n",
    "    earthquakes = earthquakes.iloc[[4,15]]\n",
    "    \n",
    "rc7_only = True\n",
    "if rc7_only:\n",
    "    earthquakes = earthquakes.iloc[[11]]\n",
    "    stas = ['B072', 'B079', 'B082', 'B087', 'B916', 'B917', 'B918', 'B921']\n",
    "    \n",
    "get_B918_only = False\n",
    "if get_B918_only:\n",
    "    earthquakes = earthquakes.iloc[[10]]\n",
    "    stas = ['B918']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "d4d11a0f-2e4b-4111-98ba-128df4e51a54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>depth</th>\n",
       "      <th>mag</th>\n",
       "      <th>magType</th>\n",
       "      <th>nst</th>\n",
       "      <th>gap</th>\n",
       "      <th>dmin</th>\n",
       "      <th>rms</th>\n",
       "      <th>...</th>\n",
       "      <th>updated</th>\n",
       "      <th>place</th>\n",
       "      <th>type</th>\n",
       "      <th>horizontalError</th>\n",
       "      <th>depthError</th>\n",
       "      <th>magError</th>\n",
       "      <th>magNst</th>\n",
       "      <th>status</th>\n",
       "      <th>locationSource</th>\n",
       "      <th>magSource</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2019-07-06T03:19:53.040Z</td>\n",
       "      <td>35.7695</td>\n",
       "      <td>-117.5993333</td>\n",
       "      <td>8</td>\n",
       "      <td>7.1</td>\n",
       "      <td>mw</td>\n",
       "      <td>77</td>\n",
       "      <td>43</td>\n",
       "      <td>0.04616</td>\n",
       "      <td>0.22</td>\n",
       "      <td>...</td>\n",
       "      <td>2024-01-04T03:30:09.226Z</td>\n",
       "      <td>Ridgecrest Earthquake Sequence</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>0.19</td>\n",
       "      <td>31.61</td>\n",
       "      <td>0.028</td>\n",
       "      <td>126</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>ci</td>\n",
       "      <td>ci</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        time latitude     longitude depth  mag magType nst  \\\n",
       "11  2019-07-06T03:19:53.040Z  35.7695  -117.5993333     8  7.1      mw  77   \n",
       "\n",
       "   gap     dmin   rms  ...                   updated  \\\n",
       "11  43  0.04616  0.22  ...  2024-01-04T03:30:09.226Z   \n",
       "\n",
       "                             place        type horizontalError depthError  \\\n",
       "11  Ridgecrest Earthquake Sequence  earthquake            0.19      31.61   \n",
       "\n",
       "   magError magNst    status locationSource magSource  \n",
       "11    0.028    126  reviewed             ci        ci  \n",
       "\n",
       "[1 rows x 22 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earthquakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "8251adc4-98a5-4018-bdd7-2c92ff9d701c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method of reading in data from IRIS uses origin times in the UTCDateTime format.\n",
    "# To get the origin times from my earthquakes file in this format, since in the CSV each\n",
    "# time unit is a separate column, I pulled each time unit out into its own variable.\n",
    "\n",
    "origin_times = earthquakes.time.values\n",
    "mags = earthquakes.mag.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "ecea425c-6a15-44db-b81d-e94e79a45baf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B001', 'B003', 'B004', 'B005', 'B006', 'B007', 'B009', 'B010',\n",
       "       'B011', 'B012', 'B018', 'B022', 'B024', 'B035', 'B081', 'B082',\n",
       "       'B086', 'B087'], dtype=object)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stas_200_microns = NA_only.loc[NA_only['GAP(m)'] == 0.0002]['BNUM'].values\n",
    "stas_200_microns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "b3467757-ce00-4a34-b5af-86e81513f416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Earthquake 1/1\n",
      "2019-07-06T03:19:53.040Z\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sydneydybing/opt/anaconda3/lib/python3.8/site-packages/obspy/io/mseed/core.py:790: UserWarning: The encoding specified in trace.stats.mseed.encoding does not match the dtype of the data.\n",
      "A suitable encoding will be chosen.\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# Process the noise data that was downloaded\n",
    "\n",
    "bad_stachan = []\n",
    "q = 0\n",
    "\n",
    "for idx in range(len(earthquakes)):\n",
    "    \n",
    "    ot = origin_times[idx]\n",
    "    print('Earthquake ' + str(idx+1) + '/' + str(len(mags)))\n",
    "    \n",
    "    if weird_events_only:\n",
    "        if idx == 0:\n",
    "            stas = ['B072', 'B076']\n",
    "\n",
    "        elif idx == 1:\n",
    "            stas = ['B928']\n",
    "    \n",
    "    print(ot)\n",
    "    \n",
    "    for sta in stas:\n",
    "        \n",
    "        # print(sta)\n",
    "        \n",
    "        for chan in chans:\n",
    "            \n",
    "            # print(chan)\n",
    "            q += 1\n",
    "            \n",
    "            try:\n",
    "                \n",
    "                if fix_dups:\n",
    "                    cut_ot = ot[:13]\n",
    "                else:\n",
    "                    cut_ot = ot[:10]\n",
    "\n",
    "                # print(cut_ot)\n",
    "\n",
    "                eq_load_dir = path_to_files + 'strain_data/noise/' + str(cut_ot) + '_M' + str(mags[idx]) + '/' + str(sta) + '/'\n",
    "                # print(eq_load_dir)\n",
    "                g = read(eq_load_dir + chan + '.mseed')\n",
    "    #                 print('Raw data')\n",
    "                # g.plot()\n",
    "\n",
    "                # Equations from Barbour and Crowell to convert to strain\n",
    "                # R = ratio of the gap between the fixed-capacitance plates and instrument diameter (0.087 m)\n",
    "\n",
    "                if sta in stas_200_microns:\n",
    "                    R = 2*10**(-4) / 0.087\n",
    "\n",
    "                else:\n",
    "                    R = 10**(-4) / 0.087\n",
    "\n",
    "                C = 10**8\n",
    "\n",
    "                # Calculating new linear extensional strains (turns from a Stream into a numpy array)\n",
    "\n",
    "                e = R * (((g[0].data)/C)/(1 - (g[0].data)/C))\n",
    "\n",
    "                times = g[0].times()\n",
    "    #                 print(g[0].stats.npts)\n",
    "\n",
    "                ## Fixing the data ##\n",
    "\n",
    "                # Identifying stations with issues using derivatives\n",
    "                # Doens't work if there are gaps - just spikes\n",
    "\n",
    "                # Taking the derivative of the timeseries\n",
    "\n",
    "                deriv_e = np.diff(np.hstack((e[0],e)))\n",
    "\n",
    "                deriv_e_min = np.min(deriv_e)\n",
    "                deriv_e_max = np.max(deriv_e)\n",
    "                deriv_e_avg = np.average(deriv_e)\n",
    "\n",
    "                if deriv_e_min <= -0.00025 or deriv_e_max >= 0.00025: # better to do this with averages or #s?\n",
    "\n",
    "                    bad_label = str(cut_ot) + '_M' + str(mags[idx]) + '.' + str(sta) + '.' + str(chan)\n",
    "                    bad_stachan.append(bad_label)\n",
    "\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "                if str(cut_ot) + '_M' + str(mags[idx]) + '.' + str(sta) + '.' + str(chan) in bad_stachan:\n",
    "\n",
    "                    # Finding the value of the messed up samples\n",
    "\n",
    "                    data_min = np.amin(e)\n",
    "\n",
    "                    # Finding the indices of the messed up samples\n",
    "\n",
    "                    i = np.where(e <= data_min)[0]\n",
    "\n",
    "                    num_bad = i.shape[0]\n",
    "\n",
    "                    # print(\"Bad station & channel - event \" + str(ot[:10]) + '_M' + str(mags[idx]) + '_' + str(sta) + '_' + str(chan) + '. ' + str(num_bad) + ' bad samples')\n",
    "\n",
    "                    # Deleting the bad samples from the data and the times arrays\n",
    "\n",
    "                    e_clean = np.delete(e, i)\n",
    "                    times_clean = np.delete(times, i)\n",
    "\n",
    "                    # Now fill in the gaps with the linear interpolation\n",
    "\n",
    "                    f = interp1d(times_clean, e_clean)\n",
    "                    e_fill = f(times)\n",
    "                    e = e_fill\n",
    "\n",
    "                else: \n",
    "                    pass\n",
    "    #                     print(\"Good station & channel - event \" + str(ot[:10]) + '_M' + str(mags[idx]) + '_' + str(sta) + '_' + str(chan))\n",
    "\n",
    "                # Normalizing unfiltered data\n",
    "\n",
    "                norm_value = np.mean(e[:200])\n",
    "                data_length = e.shape\n",
    "                normalize = np.full(data_length, norm_value)\n",
    "\n",
    "                e_norm = np.subtract(e, normalize)\n",
    "\n",
    "                # Plotting normalized fixed data\n",
    "\n",
    "    #                 plt.plot(times, e_norm*10**6)\n",
    "    #                 plt.xlim(0,100)\n",
    "    #                 plt.ylim()\n",
    "    #                 plt.xlabel('Time (s) from Earthquake Origin')\n",
    "    #                 plt.ylabel('Microstrain ($10^{-6}$ m/m)')\n",
    "    #                 plt.title(str(cut_ot) + '_M' + str(mags[idx]) + '_' + str(sta) + '_' + chan)\n",
    "\n",
    "                e_fixed = g.copy()\n",
    "                e_fixed[0].data = e_norm\n",
    "    #                 print('Fixed data')\n",
    "    #                 e_fixed.plot()\n",
    "\n",
    "                # Create folder for the event\n",
    "                eq_sta_save_dir = path_to_files + 'strain_data/noise/processed/' + str(cut_ot) + '_M' + str(mags[idx]) + '/' + str(sta) + '/'\n",
    "    #                 print(eq_sta_save_dir)\n",
    "                if os.path.isdir(eq_sta_save_dir):\n",
    "                    pass\n",
    "                else:\n",
    "                    os.makedirs(eq_sta_save_dir)\n",
    "\n",
    "                e_fixed.write(eq_sta_save_dir + chan + '.mseed', format = 'MSEED')\n",
    "\n",
    "            except:\n",
    "                # print('Passing')\n",
    "                pass\n",
    "# #                 print(str(ot[:10]) + '_M' + str(mags[idx]) + '_' + str(sta) + '_no_station')    \n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "1d7ab6e2-3958-4e1b-b62e-63a7b19422e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-07-06T03:19:53.040Z\n",
      "Earthquake 1/1\n"
     ]
    }
   ],
   "source": [
    "# Compute RMS\n",
    "\n",
    "for idx in range(len(earthquakes)):\n",
    "    \n",
    "    ot = origin_times[idx]\n",
    "    print(ot)\n",
    "    print('Earthquake ' + str(idx+1) + '/' + str(len(mags)))\n",
    "    \n",
    "    if weird_events_only:\n",
    "        if idx == 0:\n",
    "            stas = ['B072', 'B076']\n",
    "\n",
    "        elif idx == 1:\n",
    "            stas = ['B928']\n",
    "    \n",
    "    for sta in stas:\n",
    "        \n",
    "#         print(sta)\n",
    "                    \n",
    "        try:\n",
    "            \n",
    "            if fix_dups:\n",
    "                cut_ot = ot[:13]\n",
    "            else:\n",
    "                cut_ot = ot[:10]\n",
    "\n",
    "            BS1 = read(path_to_files + 'strain_data/noise/processed/' + str(cut_ot) + '_M' + str(mags[idx]) + '/' + str(sta) + '/BS1.mseed')\n",
    "            BS2 = read(path_to_files + 'strain_data/noise/processed/' + str(cut_ot) + '_M' + str(mags[idx]) + '/' + str(sta) + '/BS2.mseed')\n",
    "            BS3 = read(path_to_files + 'strain_data/noise/processed/' + str(cut_ot) + '_M' + str(mags[idx]) + '/' + str(sta) + '/BS3.mseed')\n",
    "            BS4 = read(path_to_files + 'strain_data/noise/processed/' + str(cut_ot) + '_M' + str(mags[idx]) + '/' + str(sta) + '/BS4.mseed')\n",
    "\n",
    "#             BS1.plot()\n",
    "#             BS2.plot()\n",
    "#             BS3.plot()\n",
    "#             BS4.plot()\n",
    "\n",
    "            RMS_strain = np.sqrt(((BS1[0].data)**2 + (BS2[0].data)**2 + (BS3[0].data)**2 + (BS4[0].data)**2)/4)         \n",
    "\n",
    "            times = BS1[0].times()\n",
    "\n",
    "#             plt.plot(times, BS1[0].data, label = 'BS1')\n",
    "#             plt.plot(times, BS2[0].data, label = 'BS2')\n",
    "#             plt.plot(times, BS3[0].data, label = 'BS3')\n",
    "#             plt.plot(times, BS4[0].data, label = 'BS4')\n",
    "#             plt.legend()\n",
    "#             plt.show()\n",
    "\n",
    "#             timeseries = [0.,300.]\n",
    "#             #plt.xlim(timeseries)\n",
    "#             timeseries = str(timeseries)\n",
    "\n",
    "    #            plt.xlabel('Time (s)')\n",
    "    #            plt.ylabel('RMS Microstrain ($10^{-6}$ m/m)')\n",
    "    #            plt.title(quake + ' Earthquake at PBO Station ' + sta)\n",
    "    #            plt.legend(loc = 1)\n",
    "\n",
    "            RMS_st = BS1.copy()\n",
    "            RMS_st[0].stats.channel = 'BSR'\n",
    "            RMS_st[0].data = RMS_strain\n",
    "\n",
    "#             RMS_st.plot()\n",
    "            #print(RMS_st[0].stats)\n",
    "\n",
    "            # Create folder for the event\n",
    "            eq_sta_save_dir = path_to_files + 'strain_data/noise/rms/' + str(cut_ot) + '_M' + str(mags[idx]) + '/'\n",
    "    #                 print(eq_sta_save_dir)\n",
    "            if os.path.isdir(eq_sta_save_dir):\n",
    "                pass\n",
    "            else:\n",
    "                os.makedirs(eq_sta_save_dir)\n",
    "\n",
    "            RMS_st.write(eq_sta_save_dir + sta + '.mseed', format = 'MSEED')\n",
    "                \n",
    "        except:\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e2799c-6de8-403a-9fd3-f5e1e08d0890",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6ed86a-65a1-4c1c-b640-5e5a5d23d718",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c2ae02-a19b-4d16-8742-ce1d2cc2d0a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a46008c-c3d3-48ab-99f4-eb5b19bf2e1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "207a1040-72b8-4a69-8c17-5bde217dff4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>depth</th>\n",
       "      <th>mag</th>\n",
       "      <th>magType</th>\n",
       "      <th>nst</th>\n",
       "      <th>gap</th>\n",
       "      <th>dmin</th>\n",
       "      <th>rms</th>\n",
       "      <th>...</th>\n",
       "      <th>updated</th>\n",
       "      <th>place</th>\n",
       "      <th>type</th>\n",
       "      <th>horizontalError</th>\n",
       "      <th>depthError</th>\n",
       "      <th>magError</th>\n",
       "      <th>magNst</th>\n",
       "      <th>status</th>\n",
       "      <th>locationSource</th>\n",
       "      <th>magSource</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2019-07-06T03:19:53.040Z</td>\n",
       "      <td>35.7695</td>\n",
       "      <td>-117.5993333</td>\n",
       "      <td>8</td>\n",
       "      <td>7.1</td>\n",
       "      <td>mw</td>\n",
       "      <td>77</td>\n",
       "      <td>43</td>\n",
       "      <td>0.04616</td>\n",
       "      <td>0.22</td>\n",
       "      <td>...</td>\n",
       "      <td>2024-01-04T03:30:09.226Z</td>\n",
       "      <td>Ridgecrest Earthquake Sequence</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>0.19</td>\n",
       "      <td>31.61</td>\n",
       "      <td>0.028</td>\n",
       "      <td>126</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>ci</td>\n",
       "      <td>ci</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        time latitude     longitude depth  mag magType nst  \\\n",
       "11  2019-07-06T03:19:53.040Z  35.7695  -117.5993333     8  7.1      mw  77   \n",
       "\n",
       "   gap     dmin   rms  ...                   updated  \\\n",
       "11  43  0.04616  0.22  ...  2024-01-04T03:30:09.226Z   \n",
       "\n",
       "                             place        type horizontalError depthError  \\\n",
       "11  Ridgecrest Earthquake Sequence  earthquake            0.19      31.61   \n",
       "\n",
       "   magError magNst    status locationSource magSource  \n",
       "11    0.028    126  reviewed             ci        ci  \n",
       "\n",
       "[1 rows x 22 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earthquakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b42a7288-d1ed-466a-86c2-f7873e854493",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Earthquake 1/1\n",
      "2019-07-06T03:19:53.040Z\n"
     ]
    }
   ],
   "source": [
    "# Download noise data\n",
    "\n",
    "for idx in range(len(earthquakes)):\n",
    "#     print('-----------------------------------------')\n",
    "    print('Earthquake ' + str(idx+1) + '/' + str(len(mags)))\n",
    "#     ot = str(ot_yr[idx]) + '-' + str(ot_mo[idx]) + '-' + str(ot_day[idx]) + 'T' + str(ot_hr[idx]) + ':' + str(ot_min[idx]) + ':' + str(ot_sec[idx])\n",
    "    ot = origin_times[idx]\n",
    "    print(ot)\n",
    "    stime = UTCDateTime(ot) - 120.05\n",
    "#     print(ot)\n",
    "    etime = UTCDateTime(ot)\n",
    "#     print(stime)\n",
    "#     print(etime)\n",
    "    \n",
    "    # I then looped through my stations. All of the stations I want are in the 'PB' network,\n",
    "    # and the data has the location 'T0'. This information you'll probably have to look up on\n",
    "    # the IRIS Metadata Aggregator website. \n",
    "    \n",
    "    for sta in stas:\n",
    "        net = 'PB'\n",
    "        sta = sta\n",
    "        loc = 'T0'\n",
    "        \n",
    "        # My final loop was through my four channels so I could write individual miniSEED data\n",
    "        # files for each channel.\n",
    "        \n",
    "        for chan in chans:\n",
    "            chan = chan\n",
    "            \n",
    "            # I used this try-except condition so I didn't get errors if a station didn't have \n",
    "            # data for the time window I was looking at.\n",
    "            \n",
    "            try:\n",
    "                \n",
    "                # I use the function get_waveforms to get the data from the client (IRIS), and\n",
    "                # read it into an obpsy stream object using the network, stations, etc. info\n",
    "                # that I collected earlier. I printed some stats to make sure things were working.\n",
    "                # Then I wrote the stream into a miniSEED data file and saved it onto my laptop.\n",
    "                \n",
    "                st = client.get_waveforms(net, sta, loc, chan, stime, etime)\n",
    "#                 st.plot()\n",
    "                \n",
    "                # Create folder for the event\n",
    "                if fix_dups:\n",
    "                    cut_ot = ot[:13]\n",
    "                else:\n",
    "                    cut_ot = ot[:10]\n",
    "                \n",
    "                eq_sta_save_dir = '/Users/sydneydybing/StrainProject/2024/strain_data/noise/' + str(cut_ot) + '_M' + str(mags[idx]) + '/' + str(sta) + '/'\n",
    "#                 print(eq_sta_save_dir)\n",
    "                if os.path.isdir(eq_sta_save_dir):\n",
    "                    pass\n",
    "                else:\n",
    "                    os.makedirs(eq_sta_save_dir)\n",
    "                \n",
    "                st.write(eq_sta_save_dir + chan + '.mseed', format = 'MSEED')\n",
    "            \n",
    "            # If that didn't work, my code prints out the station name and the earthquake number\n",
    "            # (a piece of information in the original earthquakes CSV that just identifies the\n",
    "            # event), and the phrase \"not found\" so I could tell what didn't work.\n",
    "            \n",
    "            except:\n",
    "                pass\n",
    "#                 print(idx, sta, chan, \"not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec68835f-cf26-4fbb-a294-a327be302215",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
